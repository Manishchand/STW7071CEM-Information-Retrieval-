{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Preprocessing Utils](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(statement):\n",
    "    # Filter out stop words & special characters\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    special_characters = '''!()-â€”[]{};:'\"\\, <>./?@#$%^&*_~+='''\n",
    "    tokens = word_tokenize(statement)\n",
    "    return [token.lower() for token in tokens if token.lower() not in stop_words and token not in special_characters]\n",
    "\n",
    "def lemmatize_word(word):\n",
    "    wordnet_tags = {\"V\": wordnet.VERB, \"R\": wordnet.ADV,\"N\": wordnet.NOUN,\"J\": wordnet.ADJ} \n",
    "    # Get parts of speech tag & determine the class in wordnet\n",
    "    pos_tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    pos_tag_class = wordnet_tags.get(pos_tag, wordnet.NOUN)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Lemmaitze with Part of Speech Tag to get the pure word\n",
    "    lemma = lemmatizer.lemmatize(word, pos=pos_tag_class)\n",
    "    return lemma\n",
    "\n",
    "def lemmatize_stmt(statement):    \n",
    "    filtered_tokens = tokenizer(statement)\n",
    "    lemmatize_tokens = []\n",
    "    for word in filtered_tokens:\n",
    "        lemma = lemmatize_word(word)\n",
    "        lemmatize_tokens.append(lemma)\n",
    "    return ' '.join(lemmatize_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Search Engine Practical](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_1_'></a>[Document Collection](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping\n",
      "\n",
      "Total Document Scrapped: 40\n"
     ]
    }
   ],
   "source": [
    "BASE_URL = 'https://pureportal.coventry.ac.uk/'\n",
    "\n",
    "print(\"Scraping\")\n",
    "\n",
    "research_output = []\n",
    "url_path = \"https://pureportal.coventry.ac.uk/en/organisations/ihw-centre-for-health-and-life-sciences-chls/publications/\"\n",
    "response = requests.get(url_path)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "li_item_tags = soup.find_all('li', class_= 'list-result-item')\n",
    "for li_item in li_item_tags:\n",
    "    research_link = li_item.find('a')['href']\n",
    "    authors = [{'author':author.text, 'url': author['href']} for author in li_item.findAll('a', 'link person')]\n",
    "    published_date = li_item.find('span', class_='date').text\n",
    "    title = li_item.find('h3', class_='title').text\n",
    "    categories = [concept.text for concept in li_item.findAll('span', class_ = 'concept')]\n",
    "    imp = lemmatize_stmt(title)  + ' ' + \\\n",
    "        \" \".join([author['url'].split('/')[-1].replace('-', ' ') for author in authors]) + ' ' + \\\n",
    "            lemmatize_stmt(\" \".join(categories)) + ' ' + \\\n",
    "        lemmatize_stmt(published_date)\n",
    "    research_output.append({\"authors\":authors, \"published_date\":published_date, \"title\":title, \"research_link\": research_link, \"categories\": categories, \"imp\": imp})\n",
    "print('\\nTotal Document Scrapped:', len(research_output))\n",
    "# Dump scraped data to json file\n",
    "with open('./scraped_data/rcih_research_output.json', 'w') as f:\n",
    "    json.dump(research_output, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc3_2_'></a>[Inverted Index Construction](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "with open('./scraped_data/rcih_research_output.json') as f:\n",
    "    rcih_research = json.loads(f.read())\n",
    "\n",
    "for doc_id, doc in enumerate(rcih_research):\n",
    "    imp = lemmatize_stmt(doc['title']  + ' ' + \" \".join(doc['categories']) + ' ' + doc['published_date']) + ' ' + \\\n",
    "            \" \".join([author['url'].split('/')[-1].replace('-', ' ') for author in doc['authors']])\n",
    "    for term in imp.split():\n",
    "        if term not in inverted_index:\n",
    "            inverted_index[term] = set()\n",
    "        inverted_index[term].add(doc_id)\n",
    "\n",
    "# Converting Set to List\n",
    "for key in inverted_index:\n",
    "    inverted_index[key] = list(inverted_index[key])\n",
    "\n",
    "with open('./scraped_data/inverted_index.json', 'w') as f:\n",
    "    json.dump(inverted_index, f, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Text Classifier](#toc0_)\n",
    "Identify whether the input scientific document is from the listed cases: \n",
    "- Health\n",
    "- Business\n",
    "- Sport\n",
    "\n",
    "Training Data link : https://www.kaggle.com/datasets/rmisra/news-category-dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_1_'></a>[Get Training Data](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_json('News_Category_Dataset_v3.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_news_df = news_df[news_df['category'].isin(['BUSINESS', \"SPORTS\", \"HEALTHY LIVING\"])]\n",
    "training_news_df.loc[training_news_df['category']== \"HEALTHY LIVING\" , 'category'] = \"HEALTH\"\n",
    "training_news_df = training_news_df[['short_description', 'category']]\n",
    "training_news_df['short_description'] = training_news_df['short_description'].apply(lemmatize_stmt)\n",
    "training_news_df.to_pickle(\"training_news_df.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_2_'></a>[MultinomialNB classifier](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['SPORTS']\n"
     ]
    }
   ],
   "source": [
    "training_news_df = pd.read_pickle('training_news_df.pkl')\n",
    "\n",
    "# Sample training data\n",
    "texts = training_news_df['short_description'].tolist()\n",
    "labels = training_news_df['category'].tolist()\n",
    "# Create feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "test_texts = [\"\"\"\n",
    "They fell short in what was virtually a must-win game, with the added significance of being on free-to-air television and with the opportunity to make their mark on the eager crowd that roared and applauded every England run and wicket with vigour.\n",
    "\n",
    "And they felt the disappointment, too - but there was a bigger picture.\n",
    "\n",
    "Ten years ago to the day, Nat Sciver-Brunt made her England debut against Pakistan at Louth, where spectators were few and far between and most likely consisted mostly of the players' families.\n",
    "\n",
    "But for England's debutant at Edgbaston, all-rounder Danielle Gibson, the experience could not be more of a contrast - and in the most brilliant, inspiring way.\n",
    "\n",
    "Gibson was clapped in to bowl like an Olympic long jumper at the start of their mark, each dot ball cheered like a wicket and every run saved greeted with raucous appreciation.\n",
    "\n",
    "There was diversity in numbers, too - children danced for the camera, groups of friends dressed up as Super Mario and lifeguards, boys donning England shirts with 'Knight' and 'Sciver-Brunt' on the back.\n",
    "\n",
    "As England fought back in the closing overs with three late wickets to ignite hopes of a shock victory, the crowd savoured every emotion with them.\n",
    "\"\"\"]\n",
    "test_X = vectorizer.transform(test_texts)\n",
    "test_predictions = classifier.predict(test_X)\n",
    "print('Predictions:', test_predictions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc4_3_'></a>[Metric Report](#toc0_)\n",
    "\n",
    "Evaluate the performance of classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.802603800140746\n",
      "Testing Accuracy: 0.7261469180973825\n",
      "F1 Score: 0.7249536376495858\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    BUSINESS       0.80      0.66      0.72      1197\n",
      "      HEALTH       0.64      0.86      0.74      1350\n",
      "      SPORTS       0.84      0.62      0.71      1006\n",
      "\n",
      "    accuracy                           0.73      3553\n",
      "   macro avg       0.76      0.71      0.72      3553\n",
      "weighted avg       0.75      0.73      0.72      3553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, classification_report\n",
    "\n",
    "# Test the classifier on training data\n",
    "train_predictions = classifier.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print('Training Accuracy:', train_accuracy)\n",
    "\n",
    "# Test the classifier on testing data\n",
    "test_predictions = classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print('Testing Accuracy:', test_accuracy)\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1 = f1_score(y_test, test_predictions, average='weighted')\n",
    "print('F1 Score:', f1)\n",
    "\n",
    "# Print classification report\n",
    "class_report = classification_report(y_test, test_predictions)\n",
    "print('\\nClassification Report:')\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
